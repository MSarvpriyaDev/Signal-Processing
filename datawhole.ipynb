{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91f77dcc-3619-4103-9857-a61ad5a9fc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cd407eb-db35-4947-97b2-1040bf1e1c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "data_folder = r\"C:\\Users\\mrpap\\OneDrive\\Desktop\\ecg signals\\Raw dataset per subject ppg\"\n",
    "\n",
    "files = [f for f in os.listdir(data_folder) if f.endswith(\".csv\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e719777-0e2b-4d79-a417-0e86cda690c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1.csv\n",
      "Processing 10.csv\n",
      "Processing 11.csv\n",
      "Processing 12.csv\n",
      "Processing 13.csv\n",
      "Processing 14.csv\n",
      "Processing 15.csv\n",
      "Processing 16.csv\n",
      "Processing 17.csv\n",
      "Processing 18.csv\n",
      "Processing 19.csv\n",
      "Processing 2.csv\n",
      "Processing 20.csv\n",
      "Processing 21.csv\n",
      "Processing 22.csv\n",
      "Processing 23.csv\n",
      "Processing 24.csv\n",
      "Processing 25.csv\n",
      "Processing 26.csv\n",
      "Processing 27.csv\n",
      "Processing 28.csv\n",
      "Processing 29.csv\n",
      "Processing 3.csv\n",
      "Processing 30.csv\n",
      "Processing 31.csv\n",
      "Processing 32.csv\n",
      "Processing 33.csv\n",
      "Processing 34.csv\n",
      "Processing 35.csv\n",
      "Processing 36.csv\n",
      "Processing 37.csv\n",
      "Processing 38.csv\n",
      "Processing 39.csv\n",
      "Processing 4.csv\n",
      "Processing 40.csv\n",
      "Processing 41.csv\n",
      "Processing 42.csv\n",
      "Processing 43.csv\n",
      "Processing 44.csv\n",
      "Processing 45.csv\n",
      "Processing 46.csv\n",
      "Processing 47.csv\n",
      "Processing 48.csv\n",
      "Processing 49.csv\n",
      "Processing 5.csv\n",
      "Processing 50.csv\n",
      "Processing 51.csv\n",
      "Processing 52.csv\n",
      "Processing 53.csv\n",
      "Processing 54.csv\n",
      "Processing 55.csv\n",
      "Processing 56.csv\n",
      "Processing 57.csv\n",
      "Processing 58.csv\n",
      "Processing 59.csv\n",
      "Processing 6.csv\n",
      "Processing 60.csv\n",
      "Processing 61.csv\n",
      "Processing 62.csv\n",
      "Processing 63.csv\n",
      "Processing 64.csv\n",
      "Processing 65.csv\n",
      "Processing 66.csv\n",
      "Processing 67.csv\n",
      "Processing 68.csv\n",
      "Processing 7.csv\n",
      "Processing 8.csv\n",
      "Processing 9.csv\n"
     ]
    }
   ],
   "source": [
    "for file in files:\n",
    "    file_path = os.path.join(data_folder, file)\n",
    "    \n",
    "    data = pd.read_csv(file_path)   # or read_csv(..., sep='\\t') for txt\n",
    "    \n",
    "    signal = data['Red (a.u)']  # column name example\n",
    "    \n",
    "    # ---- process signal here ----\n",
    "    print(f\"Processing {file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35b7bb6a-005f-4388-a58a-78d784a5f40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ppg_red = opt1['Red (a.u)'].value\n",
    "#ppg_ir=opt1['Infra Red (a.u)'].value\n",
    "fs = 25  # sampling frequency (Hz)\n",
    "#signal = ppg_red\n",
    "#t = np.arange(len(ppg_red)) / fs\n",
    "N = 100\n",
    "def demean(signal):\n",
    "    \"\"\"\n",
    "    Remove DC component (mean) from a signal.\n",
    "    \n",
    "    Parameters:\n",
    "        signal (array-like): Input signal\n",
    "    \n",
    "    Returns:\n",
    "        demeaned_signal (np.ndarray)\n",
    "        mean_value (float)\n",
    "    \"\"\"\n",
    "    mean_value = np.mean(signal)\n",
    "    demeaned_signal = signal - mean_value\n",
    "    return demeaned_signal, mean_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff2d5d6a-9f5d-4121-bf1b-63bb93bbec16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import detrend as scipy_detrend\n",
    "\n",
    "def detrend_signal(signal, detrend_type='linear'):\n",
    "    \"\"\"\n",
    "    Remove trend from a signal.\n",
    "    \n",
    "    Parameters:\n",
    "        signal (array-like): Input signal\n",
    "        detrend_type (str): 'linear' or 'constant'\n",
    "    \n",
    "    Returns:\n",
    "        detrended_signal (np.ndarray)\n",
    "    \"\"\"\n",
    "    detrended_signal = scipy_detrend(signal, type=detrend_type)\n",
    "    return detrended_signal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48b1da49-5092-411c-8247-decd638f13fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def polynomial_detrend(signal, fs, degree=2):\n",
    "    \"\"\"\n",
    "    Remove polynomial baseline trend from a signal.\n",
    "    \n",
    "    Parameters:\n",
    "        signal (array-like): Input signal\n",
    "        fs (float): Sampling frequency (Hz)\n",
    "        degree (int): Polynomial degree (e.g., 1=linear, 2=quadratic)\n",
    "    \n",
    "    Returns:\n",
    "        detrended_signal (np.ndarray)\n",
    "        trend (np.ndarray)\n",
    "        coeffs (np.ndarray)\n",
    "    \"\"\"\n",
    "    signal = np.asarray(signal)\n",
    "    t = np.arange(len(signal)) / fs\n",
    "    \n",
    "    coeffs = np.polyfit(t, signal, degree)\n",
    "    trend = np.polyval(coeffs, t)\n",
    "    \n",
    "    detrended_signal = signal - trend\n",
    "    return detrended_signal, trend, coeffs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "339dbce6-fc53-4565-9b69-ec7d57ae0ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import butter, filtfilt\n",
    "import numpy as np\n",
    "\n",
    "def bandpass_filter(signal, fs, lowcut=0.5, highcut=4.0, order=3):\n",
    "    \"\"\"\n",
    "    Apply Butterworth band-pass filter with zero-phase filtering.\n",
    "    \n",
    "    Parameters:\n",
    "        signal (array-like): Input signal\n",
    "        fs (float): Sampling frequency (Hz)\n",
    "        lowcut (float): Low cutoff frequency (Hz)\n",
    "        highcut (float): High cutoff frequency (Hz)\n",
    "        order (int): Filter order\n",
    "    \n",
    "    Returns:\n",
    "        filtered_signal (np.ndarray)\n",
    "    \"\"\"\n",
    "    signal = np.asarray(signal)\n",
    "    \n",
    "    nyq = fs / 2\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    \n",
    "    # Safety check\n",
    "    if high >= 1 or low <= 0:\n",
    "        raise ValueError(\"Cutoff frequencies must satisfy 0 < lowcut < highcut < fs/2\")\n",
    "    \n",
    "    b, a = butter(order, [low, high], btype='bandpass')\n",
    "    filtered_signal = filtfilt(b, a, signal)\n",
    "    \n",
    "    return filtered_signal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2390e2cc-c90a-4ea1-b328-cd2b6aada8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import find_peaks\n",
    "def peak_detector(signal, distance):\n",
    "    min_distance = int(0.45 * fs)\n",
    "    peaks, properties = find_peaks(\n",
    "    signal, # might change after filters\n",
    "    distance=min_distance\n",
    ")\n",
    "from scipy.signal import find_peaks\n",
    "import numpy as np\n",
    "\n",
    "def detect_ppg_peaks(signal, fs, min_rr=0.45, prominence=None, height=None):\n",
    "    \"\"\"\n",
    "    Detect systolic peaks in a PPG signal.\n",
    "    \n",
    "    Parameters:\n",
    "        signal (array-like): Filtered PPG signal\n",
    "        fs (float): Sampling frequency (Hz)\n",
    "        min_rr (float): Minimum RR interval in seconds (controls max HR)\n",
    "        prominence (float or None): Peak prominence constraint\n",
    "        height (float or None): Minimum peak height\n",
    "    \n",
    "    Returns:\n",
    "        peaks (np.ndarray): Indices of detected peaks\n",
    "        properties (dict): Peak properties from scipy\n",
    "    \"\"\"\n",
    "    signal = np.asarray(signal)\n",
    "    \n",
    "    min_distance = int(min_rr * fs)\n",
    "    \n",
    "    peaks, properties = find_peaks(\n",
    "        signal,\n",
    "        distance=min_distance,\n",
    "        prominence=prominence,\n",
    "        height=height\n",
    "    )\n",
    "    \n",
    "    return peaks, properties\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "afe4edee-4e57-4d59-b42a-0ec7a525213f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def refine_peaks(signal, peaks, fs, search_window=0.1):\n",
    "    \"\"\"\n",
    "    Refine peak locations by searching for the true local maximum.\n",
    "    \n",
    "    Parameters:\n",
    "        signal (array-like): Filtered signal\n",
    "        peaks (array-like): Initial peak indices\n",
    "        fs (float): Sampling frequency (Hz)\n",
    "        search_window (float): Half window size in seconds\n",
    "    \n",
    "    Returns:\n",
    "        refined_peaks (np.ndarray): Refined peak indices\n",
    "    \"\"\"\n",
    "    signal = np.asarray(signal)\n",
    "    peaks = np.asarray(peaks)\n",
    "    \n",
    "    window = int(search_window * fs)\n",
    "    refined_peaks = []\n",
    "\n",
    "    for p in peaks:\n",
    "        start = max(p - window, 0)\n",
    "        end   = min(p + window, len(signal))\n",
    "        local_max = np.argmax(signal[start:end]) + start\n",
    "        refined_peaks.append(local_max)\n",
    "\n",
    "    return np.array(refined_peaks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c79ea6e-6516-45f9-b93f-0b19a78f54cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def detect_ppg_valleys(signal, peaks, fs, search_window=0.6, min_segment_len=6):\n",
    "    \"\"\"\n",
    "    Detect pulse foot (valley) locations using max-slope method.\n",
    "    \n",
    "    Parameters:\n",
    "        signal (array-like): Filtered PPG signal\n",
    "        peaks (array-like): Refined systolic peak indices\n",
    "        fs (float): Sampling frequency (Hz)\n",
    "        search_window (float): Time (s) before peak to search for valley\n",
    "        min_segment_len (int): Minimum samples needed to process a segment\n",
    "    \n",
    "    Returns:\n",
    "        valleys (np.ndarray): Valley indices (NaN if not detected)\n",
    "    \"\"\"\n",
    "    signal = np.asarray(signal)\n",
    "    peaks = np.asarray(peaks)\n",
    "    \n",
    "    window = int(search_window * fs)\n",
    "    valleys = []\n",
    "\n",
    "    for p in peaks:\n",
    "        start = max(p - window, 0)\n",
    "        segment = signal[start:p]\n",
    "\n",
    "        if len(segment) < min_segment_len:\n",
    "            valleys.append(np.nan)\n",
    "            continue\n",
    "\n",
    "        # First derivative\n",
    "        d1 = np.diff(segment)\n",
    "\n",
    "        # Index of maximum upstroke\n",
    "        max_slope_idx = np.argmax(d1)\n",
    "\n",
    "        # Search minimum BEFORE max slope\n",
    "        foot_segment = segment[:max_slope_idx + 1]\n",
    "        valley_idx = np.argmin(foot_segment)\n",
    "\n",
    "        valleys.append(start + valley_idx)\n",
    "\n",
    "    return np.array(valleys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c26bc819-0a92-4567-9045-85cd047a581f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def detect_dicrotic_notches(signal, valleys, peaks, min_segment_len=6):\n",
    "    \"\"\"\n",
    "    Detect dicrotic notches between pulse foot (valley) and systolic peak.\n",
    "    \n",
    "    Parameters:\n",
    "        signal (array-like): PPG signal (band-pass or low-pass filtered)\n",
    "        valleys (array-like): Valley (pulse foot) indices\n",
    "        peaks (array-like): Refined systolic peak indices\n",
    "        min_segment_len (int): Minimum segment length to analyze\n",
    "    \n",
    "    Returns:\n",
    "        dicrotic_notches (np.ndarray): Indices of detected notches (NaN if not found)\n",
    "    \"\"\"\n",
    "    signal = np.asarray(signal)\n",
    "    valleys = np.asarray(valleys)\n",
    "    peaks = np.asarray(peaks)\n",
    "    \n",
    "    dicrotic_notches = []\n",
    "\n",
    "    for v, p in zip(valleys, peaks):\n",
    "\n",
    "        # Skip invalid beats\n",
    "        if np.isnan(v) or np.isnan(p):\n",
    "            dicrotic_notches.append(np.nan)\n",
    "            continue\n",
    "\n",
    "        v = int(v)\n",
    "        p = int(p)\n",
    "\n",
    "        if p <= v:\n",
    "            dicrotic_notches.append(np.nan)\n",
    "            continue\n",
    "\n",
    "        segment = signal[v:p]\n",
    "\n",
    "        if len(segment) < min_segment_len:\n",
    "            dicrotic_notches.append(np.nan)\n",
    "            continue\n",
    "\n",
    "        # First derivative\n",
    "        d1 = np.diff(segment)\n",
    "\n",
    "        # Zero-crossing: negative â†’ positive (local minimum)\n",
    "        candidates = np.where((d1[:-1] < 0) & (d1[1:] > 0))[0]\n",
    "\n",
    "        if len(candidates) == 0:\n",
    "            dicrotic_notches.append(np.nan)\n",
    "        else:\n",
    "            notch_idx = v + candidates[0]\n",
    "            dicrotic_notches.append(notch_idx)\n",
    "\n",
    "    return np.array(dicrotic_notches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "33694028-051a-4837-81c6-ef00f1d39537",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def refine_valid_beats(peaks, valleys, notches):\n",
    "    \"\"\"\n",
    "    Keep only beats where peak, valley, and dicrotic notch are all valid.\n",
    "    \n",
    "    Parameters:\n",
    "        peaks (array-like): Refined peak indices\n",
    "        valleys (array-like): Valley indices\n",
    "        notches (array-like): Dicrotic notch indices\n",
    "    \n",
    "    Returns:\n",
    "        peaks_v (np.ndarray): Valid peak indices\n",
    "        valleys_v (np.ndarray): Valid valley indices\n",
    "        notches_v (np.ndarray): Valid notch indices\n",
    "        valid_mask (np.ndarray): Boolean mask of valid beats\n",
    "    \"\"\"\n",
    "    peaks = np.asarray(peaks)\n",
    "    valleys = np.asarray(valleys)\n",
    "    notches = np.asarray(notches)\n",
    "    \n",
    "    valid_mask = (\n",
    "        ~np.isnan(peaks) &\n",
    "        ~np.isnan(valleys) &\n",
    "        ~np.isnan(notches)\n",
    "    )\n",
    "    \n",
    "    peaks_v   = peaks[valid_mask].astype(int)\n",
    "    valleys_v = valleys[valid_mask].astype(int)\n",
    "    notches_v = notches[valid_mask].astype(int)\n",
    "    \n",
    "    return peaks_v, valleys_v, notches_v, valid_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "53636fba-5639-495f-9996-85c9835c7bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def extract_time_domain_features(signal, peaks, valleys, notches, fs):\n",
    "    \"\"\"\n",
    "    Extract time-domain PPG pulse features.\n",
    "    \n",
    "    Parameters:\n",
    "        signal (array-like): PPG signal\n",
    "        peaks (array-like): Valid peak indices\n",
    "        valleys (array-like): Valid valley indices\n",
    "        notches (array-like): Valid dicrotic notch indices\n",
    "        fs (float): Sampling frequency (Hz)\n",
    "    \n",
    "    Returns:\n",
    "        features (dict): Dictionary of feature arrays\n",
    "    \"\"\"\n",
    "    signal = np.asarray(signal)\n",
    "\n",
    "    # Pulse amplitude\n",
    "    pulse_amplitude = signal[peaks] - signal[valleys]\n",
    "\n",
    "    # Timing features\n",
    "    rise_time = (peaks - valleys) / fs\n",
    "    notch_time = (notches - valleys) / fs\n",
    "    peak_notch_delay = (peaks - notches) / fs\n",
    "\n",
    "    # Area under pulse\n",
    "    AUP = []\n",
    "    for v, p in zip(valleys, peaks):\n",
    "        area = np.trapezoid(signal[v:p])\n",
    "        AUP.append(abs(area))\n",
    "    AUP = np.array(AUP)\n",
    "\n",
    "    # Reflection Index\n",
    "    RI = (\n",
    "        (signal[notches] - signal[valleys]) /\n",
    "        (signal[peaks]   - signal[valleys])\n",
    "    )\n",
    "\n",
    "    # Pulse width at half amplitude\n",
    "    pulse_width = []\n",
    "    for v, p in zip(valleys, peaks):\n",
    "        half_amp = signal[v] + 0.5 * (signal[p] - signal[v])\n",
    "        segment = signal[v:p]\n",
    "        idx = np.where(segment >= half_amp)[0]\n",
    "        if len(idx) > 0:\n",
    "            pulse_width.append(idx[-1] / fs)\n",
    "        else:\n",
    "            pulse_width.append(np.nan)\n",
    "    pulse_width = np.array(pulse_width)\n",
    "\n",
    "    # Inter-beat interval and heart rate\n",
    "    IBI = np.diff(peaks) / fs\n",
    "    HR  = 60 / IBI\n",
    "\n",
    "    return {\n",
    "        \"pulse_amplitude\": pulse_amplitude,\n",
    "        \"rise_time\": rise_time,\n",
    "        \"notch_time\": notch_time,\n",
    "        \"peak_notch_delay\": peak_notch_delay,\n",
    "        \"AUP\": AUP,\n",
    "        \"RI\": RI,\n",
    "        \"pulse_width\": pulse_width,\n",
    "        \"IBI\": IBI,\n",
    "        \"HR\": HR\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bdd87a33-43d0-4384-8fc2-04c43b631fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def extract_frequency_domain_features(signal, fs, max_freq=5.0):\n",
    "    \"\"\"\n",
    "    Extract frequency-domain features from PPG signal.\n",
    "    \n",
    "    Parameters:\n",
    "        signal (array-like): Preprocessed PPG signal\n",
    "        fs (float): Sampling frequency (Hz)\n",
    "        max_freq (float): Maximum frequency to analyze (Hz)\n",
    "    \n",
    "    Returns:\n",
    "        features (dict)\n",
    "        freqs (np.ndarray)\n",
    "        spectrum (np.ndarray)\n",
    "    \"\"\"\n",
    "    signal = np.asarray(signal)\n",
    "    N = len(signal)\n",
    "\n",
    "    # FFT\n",
    "    fft_vals = np.fft.fft(signal)\n",
    "    freqs = np.fft.fftfreq(N, d=1/fs)\n",
    "\n",
    "    # Positive frequencies\n",
    "    pos_mask = freqs >= 0\n",
    "    freqs_pos = freqs[pos_mask]\n",
    "    fft_mag = np.abs(fft_vals[pos_mask])\n",
    "\n",
    "    # Limit to physiological band\n",
    "    band_mask = freqs_pos <= max_freq\n",
    "    freqs_band = freqs_pos[band_mask]\n",
    "    mag_band = fft_mag[band_mask]\n",
    "\n",
    "    # ---- Frequency-domain features ----\n",
    "    dominant_freq = freqs_band[np.argmax(mag_band)]  # Hz\n",
    "    spectral_centroid = np.sum(freqs_band * mag_band) / np.sum(mag_band)\n",
    "    total_power = np.sum(mag_band**2)\n",
    "\n",
    "    return {\n",
    "        \"dominant_freq\": dominant_freq,\n",
    "        \"spectral_centroid\": spectral_centroid,\n",
    "        \"total_power\": total_power\n",
    "    }, freqs_band, mag_band\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "503e7f5f-d6a4-4d93-8298-155f888db373",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import welch\n",
    "import numpy as np\n",
    "\n",
    "def compute_welch_psd(\n",
    "    signal,\n",
    "    fs,\n",
    "    window='hann',\n",
    "    nperseg=256,\n",
    "    noverlap=None,\n",
    "    scaling='density'\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute Power Spectral Density using Welch's method.\n",
    "    \n",
    "    Parameters:\n",
    "        signal (array-like): Input signal\n",
    "        fs (float): Sampling frequency (Hz)\n",
    "        window (str): Window type\n",
    "        nperseg (int): Length of each segment\n",
    "        noverlap (int or None): Overlap between segments\n",
    "        scaling (str): 'density' or 'spectrum'\n",
    "    \n",
    "    Returns:\n",
    "        f_welch (np.ndarray): Frequency axis (Hz)\n",
    "        psd (np.ndarray): Power spectral density\n",
    "    \"\"\"\n",
    "    signal = np.asarray(signal)\n",
    "    \n",
    "    # Safety: nperseg should not exceed signal length\n",
    "    nperseg = min(nperseg, len(signal))\n",
    "    \n",
    "    f_welch, psd = welch(\n",
    "        signal,\n",
    "        fs=fs,\n",
    "        window=window,\n",
    "        nperseg=nperseg,\n",
    "        noverlap=noverlap,\n",
    "        scaling=scaling\n",
    "    )\n",
    "    \n",
    "    return f_welch, psd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3ed7a1d6-3ea3-488e-b7de-e8f1074ecb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def extract_welch_frequency_features(f_welch, psd, cardiac_band=(0.5, 4.0)):\n",
    "    \"\"\"\n",
    "    Extract frequency-domain features from Welch PSD.\n",
    "    \n",
    "    Parameters:\n",
    "        f_welch (np.ndarray): Frequency axis\n",
    "        psd (np.ndarray): Power spectral density\n",
    "        cardiac_band (tuple): (low, high) Hz\n",
    "    \n",
    "    Returns:\n",
    "        features (dict)\n",
    "    \"\"\"\n",
    "    # Dominant frequency\n",
    "    idx_peak = np.argmax(psd)\n",
    "    dominant_freq = f_welch[idx_peak]\n",
    "    HR_spectral = dominant_freq * 60\n",
    "\n",
    "    # Cardiac band power\n",
    "    band_mask = (f_welch >= cardiac_band[0]) & (f_welch <= cardiac_band[1])\n",
    "    cardiac_power = np.trapezoid(psd[band_mask], f_welch[band_mask])\n",
    "\n",
    "    # Total power\n",
    "    total_power = np.trapezoid(psd, f_welch)\n",
    "    norm_cardiac_power = cardiac_power / total_power\n",
    "\n",
    "    # Spectral centroid\n",
    "    spectral_centroid = np.sum(f_welch * psd) / np.sum(psd)\n",
    "\n",
    "    # Spectral bandwidth\n",
    "    spectral_bandwidth = np.sqrt(\n",
    "        np.sum(((f_welch - spectral_centroid)**2) * psd) / np.sum(psd)\n",
    "    )\n",
    "\n",
    "    # Spectral entropy\n",
    "    psd_norm = psd / np.sum(psd)\n",
    "    spectral_entropy = -np.sum(psd_norm * np.log2(psd_norm + 1e-12))\n",
    "\n",
    "    return {\n",
    "        \"dominant_freq\": dominant_freq,\n",
    "        \"HR_spectral\": HR_spectral,\n",
    "        \"cardiac_power\": cardiac_power,\n",
    "        \"normalized_cardiac_power\": norm_cardiac_power,\n",
    "        \"spectral_centroid\": spectral_centroid,\n",
    "        \"spectral_bandwidth\": spectral_bandwidth,\n",
    "        \"spectral_entropy\": spectral_entropy\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3ced4662-1117-4217-bbdc-a26588310d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def summarize_subject_features(\n",
    "    pulse_amplitude,\n",
    "    rise_time,\n",
    "    notch_time,\n",
    "    peak_notch_delay,\n",
    "    RI,\n",
    "    pulse_width,\n",
    "    AUP,\n",
    "    HR,\n",
    "    dominant_freq,\n",
    "    HR_spectral,\n",
    "    cardiac_power,\n",
    "    norm_cardiac_power,\n",
    "    spectral_centroid,\n",
    "    spectral_bandwidth,\n",
    "    spectral_entropy\n",
    "):\n",
    "    \"\"\"\n",
    "    Aggregate beat-wise and spectral features into subject-level features.\n",
    "    \n",
    "    Returns:\n",
    "        features (dict): One-row feature dictionary\n",
    "    \"\"\"\n",
    "    return {\n",
    "        # ---- Time-domain summaries ----\n",
    "        \"mean_pulse_amplitude\": np.nanmean(pulse_amplitude),\n",
    "        \"std_pulse_amplitude\":  np.nanstd(pulse_amplitude),\n",
    "\n",
    "        \"mean_rise_time_s\": np.nanmean(rise_time),\n",
    "        \"mean_notch_time_s\": np.nanmean(notch_time),\n",
    "        \"mean_peak_notch_delay_s\": np.nanmean(peak_notch_delay),\n",
    "\n",
    "        \"mean_RI\": np.nanmean(RI),\n",
    "\n",
    "        \"mean_pulse_width_s\": np.nanmean(pulse_width),\n",
    "        \"mean_AUP\": np.nanmean(AUP),\n",
    "\n",
    "        \"mean_HR_bpm\": np.nanmean(HR),\n",
    "        \"HR_std\": np.nanstd(HR),\n",
    "\n",
    "        # ---- Frequency-domain features ----\n",
    "        \"dominant_frequency_hz\": dominant_freq,\n",
    "        \"spectral_HR_bpm\": HR_spectral,\n",
    "\n",
    "        \"cardiac_band_power\": cardiac_power,\n",
    "        \"normalized_cardiac_power\": norm_cardiac_power,\n",
    "\n",
    "        \"spectral_centroid_hz\": spectral_centroid,\n",
    "        \"spectral_bandwidth_hz\": spectral_bandwidth,\n",
    "\n",
    "        \"spectral_entropy\": spectral_entropy\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bcf13e69-ad58-4b95-afed-0763d3d4361c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "data_folder =  r\"C:\\Users\\mrpap\\OneDrive\\Desktop\\ecg signals\\Raw dataset per subject ppg\"  # folder with PPG files\n",
    "fs = 25                # sampling frequency\n",
    "\n",
    "all_subjects = []\n",
    "\n",
    "for file in os.listdir(data_folder):\n",
    "    if not file.endswith(\".csv\"):\n",
    "        continue\n",
    "\n",
    "    file_path = os.path.join(data_folder, file)\n",
    "\n",
    "    # 1. Load signal\n",
    "    data = pd.read_csv(file_path)\n",
    "    ppg = data['Red (a.u)'].values\n",
    "\n",
    "    #ppg = data.iloc[:, 0].values\n",
    "\n",
    "    # 2. Preprocessing\n",
    "    ppg, _ = demean(ppg)\n",
    "    ppg, _, _ = polynomial_detrend(ppg, fs, degree=2)\n",
    "    ppg = bandpass_filter(ppg, fs, 0.5, 4.0)\n",
    "\n",
    "    # 3. Landmark detection\n",
    "    peaks, _ = detect_ppg_peaks(ppg, fs)\n",
    "    peaks = refine_peaks(ppg, peaks, fs)\n",
    "    valleys = detect_ppg_valleys(ppg, peaks, fs)\n",
    "    notches = detect_dicrotic_notches(ppg, valleys, peaks)\n",
    "\n",
    "    # 4. Beat validation\n",
    "    peaks_v, valleys_v, notches_v, _ = refine_valid_beats(\n",
    "        peaks, valleys, notches\n",
    "    )\n",
    "\n",
    "    if len(peaks_v) < 3:\n",
    "        continue  # skip bad subjects\n",
    "\n",
    "    # 5. Time-domain features\n",
    "    time_feats = extract_time_domain_features(\n",
    "        ppg, peaks_v, valleys_v, notches_v, fs\n",
    "    )\n",
    "\n",
    "    # 6. Frequency-domain (Welch)\n",
    "    f_welch, psd = compute_welch_psd(ppg, fs)\n",
    "    freq_feats = extract_welch_frequency_features(f_welch, psd)\n",
    "\n",
    "    # 7. Subject-level summary\n",
    "    subject_features = summarize_subject_features(\n",
    "        time_feats[\"pulse_amplitude\"],\n",
    "        time_feats[\"rise_time\"],\n",
    "        time_feats[\"notch_time\"],\n",
    "        time_feats[\"peak_notch_delay\"],\n",
    "        time_feats[\"RI\"],\n",
    "        time_feats[\"pulse_width\"],\n",
    "        time_feats[\"AUP\"],\n",
    "        time_feats[\"HR\"],\n",
    "        freq_feats[\"dominant_freq\"],\n",
    "        freq_feats[\"HR_spectral\"],\n",
    "        freq_feats[\"cardiac_power\"],\n",
    "        freq_feats[\"normalized_cardiac_power\"],\n",
    "        freq_feats[\"spectral_centroid\"],\n",
    "        freq_feats[\"spectral_bandwidth\"],\n",
    "        freq_feats[\"spectral_entropy\"]\n",
    "    )\n",
    "\n",
    "    subject_features[\"subject_id\"] = file\n",
    "    all_subjects.append(subject_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d55b973c-9460-4cf1-ab58-9e9001ab2e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mrpap\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(all_subjects)\n",
    "df.to_excel(\"PPG_Features.xlsx\", index=False)\n",
    "import os\n",
    "print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5b0fd9-f04d-450c-8219-46396b68d573",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
